name: single_vdisk_scalability

display_name: "Single vDisk Scalability"

summary:
  Test of performance scaling with one vDisk per VM

description: |
  <strong>What's this test about?</strong><br/>
  This test scales a single VM, single vdisk, single I/O test across all nodes of the cluster.
  The first datapoint is a single VM on a single node.  Subsequent iterations add a VM to each node in the cluster.
  e.g. For a 4 node cluster.
  <ul>
  <li>Iteration 1 = 1 VM  Total
  <li>Iteration 2 = 4 VMs Total
  <li>Iteration 3 = 8 VMs Total
  <li>Iteration 4 = 12 VMs Total
  <br/><br/>
  Measurement
  <ol>
    <li>Run the workload on the single VM alone, and wait for it to finish.</li>
    <li>Start the workload on the next group of VMs.</li>
    <li>Run for selected amount of time.</li>
    <li>Repeat steps 2 and 3 until the workload on all VMs has started.</li>
    <li>Wait for all workloads to finish.</li>
  </ol>
  Test Requirements
  <ul class="indented">
    <li>vCPUs: 2 vCPUs on every VM</li>
    <li>RAM: 2 GB on every VM</li>
    <li>Cluster Storage: 16GB per VM</li>
    <li>IP Addresses: 1 per VM</li>
  </ul>
  Note: This test scales with the number of nodes.

tags:
  - performance

vars:
  groups:
    display_name: "Number of VM groups"
    description: |
      The number of groups of VMs deployed across the cluster.
      Each group consists of one VM per node. A value of zero
      performs a single VM test only.
    default: 48
    min: 0
  runtime:
    display_name: "Workload run time (seconds)"
    description: |
      The amount of time, in seconds, for each group of VMs to
      run the workload before starting the workload on the
      next group.
    default: 240
    min: 1
  warmup_time:
    display_name: "Warm-up run time (seconds)"
    description: |
      The amount of time, in seconds, for all of the VMs to
      run the workload during the setup phase. This allows
      caches to warm up before measurement begins, stabilizing
      performance.
    default: 60
    min: 0
  read_percentage:
    display_name: "Workload read percentage"
    description: |
      The workload read percentage.
      Setting to 0 will result in full writes.
      Setting to 100 will result in full reads.
    default: 100
    min: 0
    max: 100
  random_percentage:
    display_name: "Workload randomness percentage"
    description: |
      The workload random percentage.
      Setting to 0 will result in fully sequential I/O workload.
      Setting to 100 will result in fully random I/O workload.
    default: 100
    min: 0
    max: 100

estimated_runtime: 1200

vms:
 - single_worker:
     count_per_node: 1
     template: ubuntu1604
     vcpus: 2
     ram_mb: 2048
     data_disks:
       count: 1
       size: 16
     nodes: "0"
{% for g in range(groups) %}
 - group_{{g}}:
     count_per_node: 1
     template: ubuntu1604
     vcpus: 2
     ram_mb: 2048
     data_disks:
       count: 1
       size: 16
{% endfor %}

workloads:
  - FIO Workload (Single VM):
      vm_group: single_worker
      config_file: workload.fio
      iogen_params:
        reporting_interval: 1
  - FIO Workload Warmup (Single VM):
      vm_group: single_worker
      config_file: workload.fio
      iogen_params:
        reporting_interval: 1
{% for g in range(groups) %}
  - FIO Workload (VM Group {{ g + 1 }}):
      vm_group: group_{{ g }}
      config_file: workload.fio
      iogen_params:
        reporting_interval: 1
      config_variables:
        read_percentage: {{ read_percentage }}
        random_percentage: {{ random_percentage }}
  - FIO Workload Warmup (VM Group {{ g + 1 }}):
      vm_group: group_{{ g }}
      config_file: workload.fio
      config_variables:
        read_percentage: {{ read_percentage }}
        random_percentage: {{ random_percentage }}
{% endfor %}

results:
  - IOPS (All VMs):
      vm_group: group_0
      result_type: generic
      unit: iops
      query: |
        sum(
          irate(
            node_disk_reads_completed_total{
              __curie_filter_scenario__
            }
          [30s])
        ) +
        sum(
          irate(
            node_disk_writes_completed_total{
              __curie_filter_scenario__
            }
          [30s])
        )
  - Latency (All VMs):
      vm_group: group_0
      result_type: generic
      unit: latency
      query: |
        (sum(
          irate(
            node_disk_read_time_seconds_total{
              __curie_filter_scenario__
            }
          [30s])
        ) +
        sum(
          irate(
            node_disk_write_time_seconds_total{
              __curie_filter_scenario__
            }
          [30s])
        )) / (
        sum(
          irate(
            node_disk_reads_completed_total{
              __curie_filter_scenario__
            }
          [30s])
        ) +
        sum(
          irate(
            node_disk_writes_completed_total{
              __curie_filter_scenario__
            }
          [30s])
        )) * 1000.0

setup:
  - cluster.CleanUp: {}
  - vm_group.CloneFromTemplate:
      vm_group_name: single_worker
{% for g in range(groups) %}
  - vm_group.CloneFromTemplate:
      vm_group_name: group_{{ g }}
{% endfor %}
  - vm_group.PowerOn:
      vm_group_name: single_worker
{% for g in range(groups) %}
  - vm_group.PowerOn:
      vm_group_name: group_{{ g }}
{% endfor %}
  - workload.PrefillRun:
      workload_name: FIO Workload (Single VM)
{% for g in range(groups) %}
  - workload.PrefillRun:
      workload_name: FIO Workload (VM Group {{ g + 1 }})
{% endfor %}
{% if warmup_time > 0 %}
  - workload.Start:
      workload_name: FIO Workload Warmup (Single VM)
      runtime_secs: {{ warmup_time }}
      async: True
{% for g in range(groups) %}
  - workload.Start:
      workload_name: FIO Workload Warmup (VM Group {{ g + 1 }})
      runtime_secs: {{ warmup_time }}
      async: True
{% endfor %}
  - workload.Wait:
      workload_name: FIO Workload Warmup (Single VM)
{% for g in range(groups) %}
  - workload.Wait:
      workload_name: FIO Workload Warmup (VM Group {{ g + 1 }})
{% endfor %}
{% endif %}
  - test.Wait:
      duration_secs: 60

run:
  - workload.Start:
      workload_name:  FIO Workload (Single VM)
      runtime_secs: {{ runtime }}
      annotate: True
      async: False
{% for g in range(groups) %}
  - workload.Start:
      workload_name: FIO Workload (VM Group {{ g + 1 }})
      runtime_secs: {{ runtime * (groups - g) }}
      annotate: True
      async: True
  - test.Wait:
      duration_secs: {{ runtime }}
{% endfor %}
{% for g in range(groups) %}
  - workload.Wait:
      workload_name: FIO Workload (VM Group {{ g + 1 }})
{% endfor %}

teardown:
  - cluster.CleanUp: {}
